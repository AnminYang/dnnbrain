#! /usr/bin/env python

"""
Use CNN activation to predict brain activation

Author: Taicheng Huang @ BNU
Email: taicheng_huang@mail.bnu.edu.cn
Reviewer:
"""

import os
import argparse
import subprocess
import numpy as np
from dnnbrain.core import model_operation
from dnnbrain.utils import iofiles

try:
    from sklearn import linear_model, model_selection
except ModuleNotFoundError:
    raise Exception('Please install sklearn in your workstation')

def main():
    parser = argparse.ArgumentParser(description='Use CNN activation to predict brain activation')
    parser.add_argument('-net',
                        type = str,
                        required = True,
                        metavar = 'CNN',
                        help = 'convolutional network name')
    parser.add_argument('-in',
                        type = str,
                        required = True,
                        metavar = 'Input Directory',
                        help = 'stimuli path')
    parser.add_argument('-layer',
                        type = int,
                        required = True,
                        metavar = 'Layer',
                        help = 'activation for specific layers')
    parser.add_argument('-channel',
                        type = int,
                        required = False,
                        metavar = 'Channel',
                        help = 'activation for specific channels')
    parser.add_argument('-brainact',
                        type = str,
                        required = True,
                        metavar = 'Nifti Activation',
                        help = 'brain activation nifti/surface file,
                                the user should correspond brain image 
                                to picture stimuli before calling this
                                script.')
    parser.add_argument('-mask',
                        type = str,
                        required = True,
                        metavar = 'Nifti mask',
                        help = 'brain activation mask')
    parser.add_argument('-model',
                        type = str,
                        required = False,
                        metavar = 'Brain Model',
                        help = 'model to predict brain activation by CNN activation, by default is GLM')
    parser.add_argument('-cvfold',
                        type = int,
                        required = True,
                        metavar = 'CVFold',
                        help = 'cross validation fold number')
    parser.add_argument('-out',
                        type = str,
                        required = True,
                        metavar = 'Output Directory',
                        help = 'output directory, output is a 4D brain image data with value in each voxel 
                                is explained_variance by linear_model')
    args = parser.parse_args()

	# See below is the framework of this command 
	# ------------------------------------
	# Streamline
	# ------------------------------------
	# 1 Call Yukun's code (activation extraction from 'core') to get CNN's activations. Parameters: -net, -in, -layer, -channel
	# 2 Extract brain activation from fMRI data (brainact and mask), and convert it as an array. Parameters: -brainact, -mask
	# 3 Iterately Call sklearn models to estimate accuracy. Parameters: -model, -cvfold.
	# 4 Map accuracy to Brain Images. Parameters: -out
	# 
	# -----------------------------------
	# psudo-code
	# -----------------------------------
	# cnnact = core.extract(net, in, layer, channel)
	# brainact = nib.load(brainact)
	# brainact_array = func_array(brainact)
	# model = sklearn.GLM(n_fold = cvfold)
	# model.fit(cnnact, brainact) # Check if needed to be iterated
	# acc = model.acc
	# project acc to brain
	# save(acc)
	# save(model)
	
	# DNN activation extraction 
    if args.net == 'alexnet':
        imgcropsize = (227,227)
    elif args.net == 'vgg11':
        imgcropsize = (227,227)
    else:
        raise Exception('Not a supported net, please contact the author for implementation.')
    imgloader_cls = iofiles.ImgLoader(args.in)
    imgloader = imgloader_cls.gen_dataloader(imgcropsize)
    dnn_act, dnn_picname = model_operation.dnn_activation(imgloader, args.net, args.layer, args.channel)
    # Reshape dnn_act and flatten its unit
    dnn_act = dnn_act.reshape((dnn_act.shape[0], dnn_act.shape[1], dnn_act.shape[2]*dnn_act.shape[3]))
    channel_num = dnn_act.shape[1]
    
    # Brain image activation extraction
    assert args.brainact.split('.')[1:] == args.mask.split('.')[1:], "Brain activation and mask are mismatched."
    brainimg_cls = iofiles.BrainImgLoader(args.brainact)
    brainimg_data_raw = brainimg_cls.load_brainimg()
    if args.mask:
        brainmask_cls = iofiles.BrainImgLoader(args.mask)
        brainmask_data_raw = brainmask_cls.load_brainimg()
    else:
        brainmask_data_raw = np.ones_like(brainimg_data_raw)
    assert brainimg_data_raw.shape == brainmask_data.shape, "Shape of brainact and mask need to be same."
    brainimg_data_raw = brainimg_data_raw*brainmask_data_raw
    
    # For simplicity, rearrange brainimg_data as the same dimension with pic*voxel.
    if args.brainact.endswith('.mgz') or args.brainact.endswith('mgh'):
        brainimg_data = brainimg_data.transpose(3,1,2,0)
        brainmask_data = brainmask_data_raw.transpose(3,1,2,0)
    else:
        brainimg_data = 1.0*brainimg_data_raw
        brainmask_data = 1.0*brainmask_data_raw
    # Image shape is pic*voxel and idx record location of activation
    brainact_idx = np.transpose(np.where(brainmask_data[0,...]!=0))
	
    # Initialize machine learning models
    if not args.model:
        args.model = 'lasso'
    if args.model == 'glm':
        model = linear_model.LinearRegression()
    elif args.model == 'lasso':
        model = linear_model.Lasso()
    else:
        raise Exception('Not supported yet, please contact the author for implementation.')

    # output image: channel*voxels
    out_brainimg = np.zeros((channel_num, *brainimg_data.shape[1:]))
    # Tidy DNN activation data and brain activation data
    for i in range(channel_num):
        # nsamples(pics)*nfeatures(units)
        dnnact_list = dnn_act[:,i,:]
        for b_idx in range(brainact_idx):
            # nsamples(pics)*nfeatures(voxel)
            brainact_list = brainimg_data[:, tuple(b_idx)][:,None]
            # Cross validation
            scores = model_selection.cross_val_score(model, dnn_act, brainimg, scroing='explained_variance', cv=args.cvfold)
            out_brainimg[i, tuple(b_idx)] = scores
            
    if args.brainact.endswith('mgz') or args.brainact.endswith('mgh'):
        out_brainimg = out_brainimg.transpose((3,1,2,0))
    # Here only return the out_brainimg but not save it in hardware, because I haven't implement ways to save image data.
    return out_brainimg
    
        



if __name__ == '__main__':
    main()
