#! /usr/bin/env python

"""
Use CNN activation to predict brain activation

Author: Taicheng Huang @ BNU
Email: taicheng_huang@mail.bnu.edu.cn
Reviewer:
"""

import os
import argparse
import subprocess
import numpy as np
from torchvision import transforms
from dnnbrain.core import model_operation
from dnnbrain.utils import iofiles

try:
    from sklearn import linear_model, model_selection, decomposition
except ModuleNotFoundError:
    raise Exception('Please install sklearn in your workstation')

def main():
    parser = argparse.ArgumentParser(description='Use CNN activation to predict brain activation')
    parser.add_argument('-net',
                        type = str,
                        required = True,
                        metavar = 'CNN',
                        help = 'convolutional network name')
    parser.add_argument('-in',
                        type = str,
                        required = True,
                        metavar = 'Input Directory',
                        help = 'stimuli path')
    parser.add_argument('-layer',
                        type = int,
                        required = True,
                        metavar = 'Layer',
                        help = 'activation for specific layers')
    parser.add_argument('-channel',
                        type = int,
                        required = False,
                        metavar = 'Channel',
                        help = 'activation for specific channels')
    parser.add_argument('-csv',
                        type = int,
                        required = True,
                        metavar = 'picture stimuli csv',
                        help = 'table contains picture names, conditions and picture onset time.
                                This csv_file helps us connect cnn activation to brain images.
                                Please organize your information as:
                                ---------------------------------------
                                stimID     condition   onset(optional) measurement(optional)
                                face1.png  face        1.1             3
                                face2.png  face        3.1             5
                                scene1.png scene       5.1             4'
                        )
    parser.add_argument('-brainact',
                        type = str,
                        required = True,
                        metavar = 'Nifti Activation',
                        help = 'brain activation nifti/surface file,
                                user should correspond brain image 
                                to picture stimuli before calling this
                                script.')
    parser.add_argument('-mask',
                        type = str,
                        required = True,
                        metavar = 'Nifti mask',
                        help = 'brain activation mask')
    parser.add_argument('-model',
                        type = str,
                        required = False,
                        metavar = 'Brain Model',
                        choices = ['lasso', 'glm'],
                        help = 'model to predict brain activation by CNN activation, by default is lasso.
                                lasso analysis is a multivariate analysis and we will first decompose activation
                                data of DNN into 200 dimension and then calculate explained variance by using 
                                cross validation. 
                                glm analysis is a univariate analysis, we will do linear cross validation in each
                                brain image voxel with each units and return the maximum explained variance as 
                                the explained variance of brain activation.')
    parser.add_argument('-cvfold',
                        type = int,
                        required = False,
                        default = 2,
                        metavar = 'CVFold',
                        help = 'cross validation fold numbers')
    parser.add_argument('-out',
                        type = str,
                        required = True,
                        metavar = 'Output Directory',
                        help = 'output directory, output is a 4D brain image data with value in each voxel 
                                is explained_variance by linear_model')
    args = parser.parse_args()

	# See below is the framework of this command 
	# ------------------------------------
	# Streamline
	# ------------------------------------
	# 1 Call Yukun's code (activation extraction from 'core') to get CNN's activations. Parameters: -net, -in, -layer, -channel
	# 2 Extract brain activation from fMRI data (brainact and mask), and convert it as an array. Parameters: -brainact, -mask
	# 3 Iterately Call sklearn models to estimate accuracy. Parameters: -model, -cvfold.
	# 4 Map accuracy to Brain Images. Parameters: -out
	# 
	# -----------------------------------
	# psudo-code
	# -----------------------------------
	# cnnact = core.extract(net, in, layer, channel)
	# brainact = nib.load(brainact)
	# brainact_array = func_array(brainact)
	# model = sklearn.GLM(n_fold = cvfold)
	# model.fit(cnnact, brainact) # Check if needed to be iterated
	# acc = model.acc
	# project acc to brain
	# save(acc)
	# save(model)
	
	# DNN activation extraction 
    if args.net == 'alexnet':
        imgcropsize = (227,227)
    elif args.net == 'vgg11':
        imgcropsize = (227,227)
    else:
        raise Exception('Not a supported net, please contact the author for implementation.')
        
    transform = transforms.Compose([transform.Resize(imgcropsize),
                                    transforms.ToTensor()])                            
    picdataset = iofiles.PicDataset(args.csv, args.in, transform=transform)
    dnn_act = model_operation.dnn_activation(picdataset, args.net, args.layer, args.channel)
    
    # Reshape dnn_act and flatten its unit
    channel_num = dnn_act.shape[1]
    dnn_act = dnn_act.reshape((dnn_act.shape[0], channel_num, dnn_act.shape[2]*dnn_act.shape[3]))
    
    # Brain image activation extraction
    assert args.brainact.split('.')[1:] == args.mask.split('.')[1:], "Brain activation and mask are mismatched."
    brainimg_data_raw, header = iofiles.load_brainimg(args.brainact)
    if args.mask:
        brainmask_data_raw, header = iofiles.load_brainimg(args.mask)
    else:
        brainmask_data_raw = np.ones_like(brainimg_data_raw)
    assert brainimg_data_raw.shape == brainmask_data.shape, "Shape of brainact and mask need to be same."
    brainimg_data_raw = brainimg_data_raw*brainmask_data_raw
    
    # For simplicity, rearrange brainimg_data as the same dimension with pic*voxel.
    if args.brainact.endswith('.mgz') or args.brainact.endswith('mgh'):
        brainimg_data = brainimg_data.transpose(3,1,2,0)
        brainmask_data = brainmask_data_raw.transpose(3,1,2,0)
    else:
        brainimg_data = 1.0*brainimg_data_raw
        brainmask_data = 1.0*brainmask_data_raw
    # Image shape is pic*voxel and idx record location of activation
    brainact_idx = np.transpose(np.where(brainmask_data[0,...]!=0))
	
    # Initialize machine learning models
    if not args.model:
        args.model = 'lasso'
    if args.model == 'glm':
        args.model = linear_model.LinearRegression()
    elif args.model == 'lasso':
        model = linear_model.Lasso()
    else:
        raise Exception('Not supported yet, please contact the author for implementation.')

    # output image: channel*voxels
    out_brainimg = np.zeros((channel_num, *brainimg_data.shape[1:]))
    # Tidy DNN activation data and brain activation data
    
    # Multivariate regression analysis
    if args.model == 'lasso':
        pca = decomposition.PCA(n_components=200)
        for i in range(channel_num):
            # nsamples(pics)*nfeatures(units)
            dnnact_list = dnn_act[:,i,:]
            for b_idx in range(brainact_idx):
                # nsamples(pics)*nfeatures(voxel)
                brainact_list = brainimg_data[:, tuple(b_idx)][:,None]
                # Decrease dimension using PCA
                dnn_act_pca = pca.fit_transform(dnnact_list)
                # Cross validation
                scores = model_selection.cross_val_score(model, dnn_act_pca, brainact_list, scroing='explained_variance', cv=args.cvfold)
                out_brainimg[i, tuple(b_idx)] = scores
                
    # Univariate regression analysis
        # get the maximum value of explained_variance across all DNN units in a channel
    elif args.model == 'glm':
        for i in range(channel_num):
            # nsamples(pics)*nfeatures(units)
            dnnact_list = dnn_act[:,i,:]
            # Iterate across units
            for b_idx in range(brainact_idx):
                scores_tmp = []
                for j in range(dnnact_list.shape[1]): 
                    brainact_list = brainimg_data[:,tuple(b_idx)][:,None]
                    dnnactlist_tmp = dnnact_list[:,j][:,None]
                    scores_tmp.append(model_selection.cross_val_score(model, dnnactlist_tmp, brainact_list, scoring='explained_variance', cv=args.cvfold))
                out_brainimg[i, tuple(b_idx)] = np.max(scores_tmp)
                                    
    if args.brainact.endswith('mgz') or args.brainact.endswith('mgh'):
        out_brainimg = out_brainimg.transpose((3,1,2,0))
    
    # Save image into hardware
    iofiles.save_brainimg(args.out, out_brainimg, header)

if __name__ == '__main__':
    main()
